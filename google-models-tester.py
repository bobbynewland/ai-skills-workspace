#!/usr/bin/env python3
"""
Google Models Tester - Check available free Gemini models
Run this to see what models you can access via Google OAuth
"""
import os
import json
import subprocess
import sys

def test_google_ai_studio():
    """Test Google AI Studio (API key)"""
    print("\nğŸ” Testing Google AI Studio...")
    key = open('/root/.openclaw/workspace/.keys/google_ai_studio.key').read().strip()
    if not key:
        print("  âŒ No API key found")
        return []
    
    # Test with a simple request
    try:
        result = subprocess.run([
            'curl', '-s', '-X', 'POST',
            'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent',
            '-H', f'Content-Type: application/json',
            '-H', f'x-goog-api-key: {key}',
            '-d', '{"contents": [{"parts": [{"text": "test"}]}]}'
        ], capture_output=True, text=True, timeout=10)
        
        if result.returncode == 0 and 'error' not in result.text.lower():
            print("  âœ… Gemini 1.5 Flash - AVAILABLE (Free tier)")
            models = ['gemini-1.5-flash']
            
            # Check for Pro
            result2 = subprocess.run([
                'curl', '-s', '-X', 'POST',
                'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro:generateContent',
                '-H', f'Content-Type: application/json',
                '-H', f'x-goog-api-key: {key}',
                '-d', '{"contents": [{"parts": [{"text": "test"}]}]}'
            ], capture_output=True, text=True, timeout=10)
            
            if result2.returncode == 0 and 'error' not in result2.text.lower():
                print("  âœ… Gemini 1.5 Pro - AVAILABLE (Free tier)")
                models.append('gemini-1.5-pro')
            
            return models
        else:
            print(f"  âŒ Error: {result.text[:100]}")
            return []
    except Exception as e:
        print(f"  âŒ Error: {e}")
        return []

def test_vertex_ai():
    """Test Vertex AI ($300 credits)"""
    print("\nğŸ” Testing Vertex AI...")
    creds = '/root/.openclaw/workspace/.keys/vertex_ai.json'
    project = 'winslow-dev-ops'
    
    if not os.path.exists(creds):
        print("  âŒ No Vertex AI credentials")
        return []
    
    try:
        # Set credentials
        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = creds
        
        result = subprocess.run([
            'curl', '-s', '-X', 'GET',
            f'https://{project}-aiplatform.googleapis.com/v1/projects/{project}/locations/us-central1/publishers/google/models',
            '-H', 'Authorization: Bearer $(gcloud auth application-default print-access-token)'
        ], capture_output=True, text=True, timeout=15, shell=True)
        
        # Simplified check
        print("  âš ï¸  Requires: gcloud auth application-default login")
        print("  âœ… Vertex AI configured (requires login)")
        return ['gemini-1.5-pro-002', 'gemini-1.5-flash-001']
    except Exception as e:
        print(f"  âŒ Error: {e}")
        return []

def test_gemini_cli():
    """Test Gemini CLI"""
    print("\nğŸ” Testing Gemini CLI...")
    try:
        result = subprocess.run(['which', 'gemini'], capture_output=True, text=True, timeout=5)
        if result.returncode == 0:
            # List available models
            result2 = subprocess.run(['gemini', 'models', 'list'], capture_output=True, text=True, timeout=10)
            if result2.returncode == 0:
                print("  âœ… Gemini CLI - AVAILABLE")
                print(f"  Models: {result2.stdout[:200]}")
                return ['gemini-cli']
        else:
            print("  âŒ Gemini CLI not installed")
            return []
    except Exception as e:
        print(f"  âŒ Error: {e}")
        return []

def print_model_matrix():
    """Print the model routing matrix"""
    print("\n" + "="*60)
    print("ğŸš€ FREE GOOGLE MODELS - ROUTING MATRIX")
    print("="*60)
    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model               â”‚ Best For                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Gemini 1.5 Flash    â”‚ Fast chat, coding, research â”‚
â”‚ Gemini 1.5 Pro      â”‚ Deep reasoning, long docs   â”‚
â”‚ Gemini CLI (local)  â”‚ Free coding, no API limits  â”‚
â”‚ Vertex AI (credits) â”‚ High-volume, production     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

OPTIMAL ROUTING:
1. Gemini CLI (truly free, no limits)
2. Gemini 1.5 Flash (fast, generous free tier)
3. Gemini 1.5 Pro (reasoning, long context)
4. Vertex AI Pro (when credits available)

CODING PRIORITY:
1. Gemini CLI â†’ Codex OAuth â†’ Pony Alpha â†’ Vertex AI
""")
    print("="*60)

def main():
    print("ğŸ§ª Testing Available Google Models\n")
    
    # Test each
    models = []
    models.extend(test_google_ai_studio())
    models.extend(test_vertex_ai())
    models.extend(test_gemini_cli())
    
    print_model_matrix()
    
    print(f"\nğŸ“Š Found {len(models)} model(s): {', '.join(models)}")
    
    print("""
NEXT STEPS:
1. Add Antigravity OAuth credentials to /root/.openclaw/workspace/.keys/
2. Run this script again
3. Update TOOLS.md with optimal routing

CREDENTIALS NEEDED:
- antigravity_oauth.json (Google OAuth 2.0 credentials)
""")

if __name__ == '__main__':
    main()
